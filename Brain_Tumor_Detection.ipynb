{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiszVgzrWBTH",
        "outputId": "d0d2e721-bb42-4083-e485-2a27d2adc338"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "/content/drive/MyDrive/Brain Tumor.zip\n",
        "\n"
      ],
      "metadata": {
        "id": "SQvANrUmWL-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "drive_path = '/content/drive/MyDrive/Brain Tumor.zip'\n",
        "zip_path = drive_path\n",
        "extract_path = '/content/brain_tumor_data'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "train_data_dir = os.path.join(extract_path, 'Training')\n",
        "test_data_dir = os.path.join(extract_path, 'Testing')\n",
        "\n",
        "filepaths, labels = [], []\n",
        "\n",
        "def collect_data(data_dir):\n",
        "    for class_folder in os.listdir(data_dir):\n",
        "        class_path = os.path.join(data_dir, class_folder)\n",
        "        if os.path.isdir(class_path):\n",
        "            for file in os.listdir(class_path):\n",
        "                if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    filepaths.append(os.path.join(class_path, file))\n",
        "                    labels.append(class_folder)\n",
        "\n",
        "collect_data(train_data_dir)\n",
        "collect_data(test_data_dir)\n",
        "\n",
        "data_df = pd.DataFrame({'filepaths': filepaths, 'labels': labels})\n",
        "train_df, temp_df = train_test_split(data_df, train_size=0.7, shuffle=True, random_state=42)\n",
        "valid_df, test_df = train_test_split(temp_df, train_size=0.5, shuffle=True, random_state=42)\n",
        "\n",
        "batch_size = 16\n",
        "img_size = (224, 224)\n",
        "tr_gen = ImageDataGenerator(rescale=1./255)\n",
        "ts_gen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_gen = tr_gen.flow_from_dataframe(train_df, x_col='filepaths', y_col='labels', target_size=img_size, class_mode='categorical', color_mode='rgb', shuffle=True, batch_size=batch_size)\n",
        "valid_gen = ts_gen.flow_from_dataframe(valid_df, x_col='filepaths', y_col='labels', target_size=img_size, class_mode='categorical', color_mode='rgb', shuffle=True, batch_size=batch_size)\n",
        "test_gen = ts_gen.flow_from_dataframe(test_df, x_col='filepaths', y_col='labels', target_size=img_size, class_mode='categorical', color_mode='rgb', shuffle=False, batch_size=batch_size)\n",
        "\n",
        "img_shape = (224, 224, 3)\n",
        "class_count = len(train_gen.class_indices.keys())\n",
        "\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=img_shape),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(class_count, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adamax(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "epochs = 10\n",
        "history = model.fit(train_gen, epochs=epochs, validation_data=valid_gen, shuffle=False)\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/Brain Tumor Detection/mlp_model.h5\"\n",
        "model.save(model_path)\n",
        "print(f\"Model saved at {model_path}\")"
      ],
      "metadata": {
        "id": "gLafRuzUWEdU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "106180af-3358-44fe-ec67-6cc07e8c5ca9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 4916 validated image filenames belonging to 4 classes.\n",
            "Found 1053 validated image filenames belonging to 4 classes.\n",
            "Found 1054 validated image filenames belonging to 4 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 525ms/step - accuracy: 0.5507 - loss: 2.9561 - val_accuracy: 0.7436 - val_loss: 0.7280\n",
            "Epoch 2/10\n",
            "\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 499ms/step - accuracy: 0.7733 - loss: 0.6654 - val_accuracy: 0.7740 - val_loss: 0.7155\n",
            "Epoch 3/10\n",
            "\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 480ms/step - accuracy: 0.7977 - loss: 0.5534 - val_accuracy: 0.8101 - val_loss: 0.5850\n",
            "Epoch 4/10\n",
            "\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 523ms/step - accuracy: 0.8332 - loss: 0.4661 - val_accuracy: 0.7417 - val_loss: 0.7871\n",
            "Epoch 5/10\n",
            "\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 485ms/step - accuracy: 0.8232 - loss: 0.4754 - val_accuracy: 0.8234 - val_loss: 0.5636\n",
            "Epoch 6/10\n",
            "\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 497ms/step - accuracy: 0.8846 - loss: 0.3022 - val_accuracy: 0.7721 - val_loss: 0.7182\n",
            "Epoch 7/10\n",
            "\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 501ms/step - accuracy: 0.8899 - loss: 0.2978 - val_accuracy: 0.7673 - val_loss: 0.7880\n",
            "Epoch 8/10\n",
            "\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 541ms/step - accuracy: 0.8729 - loss: 0.3477 - val_accuracy: 0.8234 - val_loss: 0.6038\n",
            "Epoch 9/10\n",
            "\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 501ms/step - accuracy: 0.9220 - loss: 0.2057 - val_accuracy: 0.7768 - val_loss: 0.8145\n",
            "Epoch 10/10\n",
            "\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 507ms/step - accuracy: 0.9256 - loss: 0.2006 - val_accuracy: 0.8509 - val_loss: 0.5430\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved at /content/drive/MyDrive/Brain Tumor Detection/mlp_model.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0_roJDC2Xs0C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}